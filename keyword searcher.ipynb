{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29319218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Email from Evelyn to an Unknown Recipient:\n",
      "\"Subject: Discreet Sale Inquiry\n",
      "\n",
      "Dear [Redacted],\n",
      "\n",
      "I hope this message finds you well. Given your interest in rare books, I wanted to discreetly inquire if you might know someone willing to purchase a unique item from our collection. It's a sensitive matter, and discretion is paramount.\n",
      "\n",
      "Best,\n",
      "Evelyn\"\n",
      "\n",
      "Response from Henry Clarke to Evelyn (Found in Sent Items):\n",
      "\"Subject: Re: Discreet Sale Inquiry\n",
      "\n",
      "Evelyn,\n",
      "\n",
      "I must express my strong opposition to this course of action. Selling any part of the collection, especially in such a manner, goes against everything the library stands for. We need to discuss this further.\n",
      "\n",
      "Henry\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'email_exchanges.txt'\n",
    "infile = open(filename, 'r') \n",
    "text = infile.read()\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d5169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sale Inquiry Dear', 0.004053646187548878)\n",
      "('Unknown Recipient', 0.005020995962974037)\n",
      "('Discreet Sale Inquiry', 0.0063017981494881345)\n",
      "('Inquiry Dear', 0.016882166591627046)\n",
      "('Discreet Sale', 0.022498082081573074)\n",
      "('Sale Inquiry Evelyn', 0.02260013089547158)\n",
      "('Sale Inquiry', 0.030397482404870443)\n",
      "('hope this message', 0.041054384801966146)\n",
      "('message finds', 0.041054384801966146)\n",
      "('Redacted', 0.053170544955891054)\n",
      "('Recipient', 0.06499846771761057)\n",
      "('Dear', 0.06499846771761057)\n",
      "('Unknown', 0.07686198901101354)\n",
      "('Subject', 0.07913972030159284)\n",
      "('Evelyn', 0.08123727648378978)\n",
      "('Inquiry Evelyn', 0.09051065130516404)\n",
      "('Discreet', 0.09595090397857892)\n",
      "('Sale', 0.11218937646215914)\n",
      "('Inquiry', 0.12770986217016472)\n",
      "('Email', 0.15946231285963994)\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 20\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "keywords = custom_kw_extractor.extract_keywords(text)\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b89317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yake\n",
      "  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tabulate in ./anaconda3/lib/python3.9/site-packages (from yake) (0.8.10)\n",
      "Requirement already satisfied: click>=6.0 in ./anaconda3/lib/python3.9/site-packages (from yake) (8.1.7)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (from yake) (1.23.5)\n",
      "Collecting segtok (from yake)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.9/site-packages (from yake) (3.1)\n",
      "Requirement already satisfied: jellyfish in ./anaconda3/lib/python3.9/site-packages (from yake) (1.0.1)\n",
      "Requirement already satisfied: regex in ./anaconda3/lib/python3.9/site-packages (from segtok->yake) (2023.10.3)\n",
      "Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m380.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: segtok, yake\n",
      "Successfully installed segtok-1.5.11 yake-0.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403c0d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake_nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in ./anaconda3/lib/python3.9/site-packages (from rake_nltk) (3.8.1)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.9/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.65.0)\n",
      "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: rake_nltk\n",
      "Successfully installed rake_nltk-1.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6eb6e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['might know someone willing', 'discreet sale inquiry dear', 'discreet sale inquiry evelyn', 'sent items ):', 'unknown recipient', 'unique item', 'strong opposition', 'sensitive matter', 'redacted ],', 'rare books', 'must express', 'message finds', 'library stands', 'discreetly inquire', 'henry clarke', 'evelyn', 'evelyn', 'evelyn', 'henry', 'well', 'wanted', 'subject', 'subject', 'selling', 'response', 'purchase', 'part', 'paramount', 'need', 'manner', 'interest', 'hope', 'goes', 'given', 'found', 'everything', 'especially', 'email', 'discuss', 'discretion', 'course', 'collection', 'collection', 'best', 'action']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_nltk_var = Rake()\n",
    "rake_nltk_var.extract_keywords_from_text(text)\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421baff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./anaconda3/lib/python3.9/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.local/lib/python3.9/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./anaconda3/lib/python3.9/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in ./anaconda3/lib/python3.9/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.9/site-packages (from FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Requirement already satisfied: pyfume in ./anaconda3/lib/python3.9/site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.9/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.9/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.9/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in ./anaconda3/lib/python3.9/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in ./anaconda3/lib/python3.9/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in ./anaconda3/lib/python3.9/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa2ce60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keywords\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(keywords(text))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "print(keywords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf3f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the word for which related words are required: rare\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m corpus \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m     22\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the word for which related words are required: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m related_words \u001b[38;5;241m=\u001b[39m \u001b[43mextract_related_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop similar words to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(keyword, related_words))\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mextract_related_words\u001b[0;34m(corpus, keyword)\u001b[0m\n\u001b[1;32m     10\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(keyword_vector, tfidf_matrix)\n\u001b[1;32m     12\u001b[0m top_similar_words_indices \u001b[38;5;241m=\u001b[39m cosine_similarities\u001b[38;5;241m.\u001b[39margsort()[\u001b[38;5;241m0\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m top_similar_words \u001b[38;5;241m=\u001b[39m [tfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names()[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top_similar_words_indices]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_similar_words\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(keyword_vector, tfidf_matrix)\n\u001b[1;32m     12\u001b[0m top_similar_words_indices \u001b[38;5;241m=\u001b[39m cosine_similarities\u001b[38;5;241m.\u001b[39margsort()[\u001b[38;5;241m0\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m top_similar_words \u001b[38;5;241m=\u001b[39m [\u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m()[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top_similar_words_indices]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_similar_words\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def extract_related_words(corpus, keyword):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    keyword_vector = tfidf_vectorizer.transform([keyword])\n",
    "    cosine_similarities = cosine_similarity(keyword_vector, tfidf_matrix)\n",
    "\n",
    "    top_similar_words_indices = cosine_similarities.argsort()[0][::-1][1:4]\n",
    "    top_similar_words = [tfidf_vectorizer.get_feature_names()[idx] for idx in top_similar_words_indices]\n",
    "\n",
    "    return top_similar_words\n",
    "\n",
    "\n",
    "\n",
    "corpus = text\n",
    "\n",
    "\n",
    "keyword = input(\"Enter the word for which related words are required: \")\n",
    "\n",
    "related_words = extract_related_words(corpus, keyword)\n",
    "print(\"Top similar words to '{}': {}\".format(keyword, related_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bba0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
